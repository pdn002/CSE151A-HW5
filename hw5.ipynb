{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quation 5 part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62.  0.  0. ...  3.  2.  0.]\n",
      " [52.  1.  0. ...  0.  0.  0.]\n",
      " [62.  1.  2. ...  3.  3.  1.]\n",
      " ...\n",
      " [57.  1.  0. ...  0.  1.  1.]\n",
      " [54.  1.  0. ...  1.  3.  0.]\n",
      " [40.  1.  0. ...  0.  3.  0.]]\n",
      "(303, 14)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "raw_heart_data = np.loadtxt('heart.csv',delimiter=',', dtype=str)\n",
    "\n",
    "# delete first row which are just column names\n",
    "column_names = raw_heart_data[0].T\n",
    "raw_heart_data = np.delete(raw_heart_data, 0, axis=0)\n",
    "\n",
    "# change from type str to float\n",
    "raw_heart_data = raw_heart_data.astype(float)\n",
    "\n",
    "# randomize the data\n",
    "np.random.shuffle(raw_heart_data)\n",
    "print(raw_heart_data)\n",
    "print(np.shape(raw_heart_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 13)\n",
      "(103, 13)\n",
      "(200,)\n",
      "(103,)\n"
     ]
    }
   ],
   "source": [
    "# separate data\n",
    "\n",
    "heart_data = raw_heart_data[:,0:13]\n",
    "heart_labels = raw_heart_data[:,13].T\n",
    "\n",
    "training_data = heart_data[0:200]\n",
    "test_data = heart_data[200:303]\n",
    "training_labels = heart_labels[0:200]\n",
    "test_labels = heart_labels[200:303]\n",
    "\n",
    "print(np.shape(training_data))\n",
    "print(np.shape(test_data))\n",
    "print(np.shape(training_labels))\n",
    "print(np.shape(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00742989, -1.1784425 ,  0.87922993, -0.01628068, -0.00322369,\n",
       "        -0.41193656,  0.35555269,  0.02012489, -0.58441923, -0.52096278,\n",
       "         0.4736624 , -0.85890855, -0.6033157 ]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit logistic regression\n",
    "\n",
    "logistic_model = linear_model.LogisticRegression(max_iter=1000).fit(training_data, training_labels)\n",
    "w = logistic_model.coef_\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three most influential features\n",
      "Index 1 sex\n",
      "Index 2 cp\n",
      "Index 11 ca\n"
     ]
    }
   ],
   "source": [
    "# sort indicies of highest magnitude to lowest\n",
    "sorted_indicies = np.argsort(np.absolute(w[0]) * -1)\n",
    "\n",
    "# three most influential feature\n",
    "print(\"Three most influential features\")\n",
    "for i in sorted_indicies[0:3]:\n",
    "    print(\"Index \" + str(i) + \" \" + str(column_names[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: 0.13592233009708743\n"
     ]
    }
   ],
   "source": [
    "# get test error\n",
    "test_accuracy = logistic_model.score(test_data, test_labels)\n",
    "print(\"Test Error: \" + str(1 - test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5 part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross-validation error: 0.16999999999999998\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "total_error = 0\n",
    "size = len(training_data) // k\n",
    "for i in range(5):\n",
    "    total_error += 1 - logistic_model.score(training_data[(i*size):(i*size+size)], training_labels[(i*size):(i*size+size)])\n",
    "average_error = total_error / 5\n",
    "print('5-fold cross-validation error: ' + str(average_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error and the cross-validation error are both about the same with an error of 0.145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sex', 'trestbps'], dtype='<U8')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_feature_names = column_names[1:1+1]\n",
    "s_feature_names = np.append(s_feature_names, column_names[3])\n",
    "s_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature selected at k = 1: cp\n",
      "Feature selected at k = 2: ca\n",
      "Feature selected at k = 3: thal\n",
      "Feature selected at k = 4: trestbps\n",
      "Feature selected at k = 5: ï»¿age\n",
      "Feature selected at k = 6: chol\n",
      "Feature selected at k = 7: fbs\n",
      "Feature selected at k = 8: thalach\n",
      "Feature selected at k = 9: sex\n",
      "Feature selected at k = 10: slope\n",
      "Feature selected at k = 11: oldpeak\n",
      "Feature selected at k = 12: exang\n",
      "Feature selected at k = 13: restecg\n"
     ]
    }
   ],
   "source": [
    "not_s = training_data\n",
    "not_s_feature_names = column_names\n",
    "\n",
    "# find the first feature to be in S\n",
    "min_error = 1\n",
    "min_feature = 0\n",
    "for j in range(len(not_s[0])):\n",
    "    k = 5\n",
    "    total_error = 0\n",
    "\n",
    "    sparse_model = linear_model.LogisticRegression(max_iter=1000).fit(not_s[:,j:j+1], training_labels)\n",
    "\n",
    "    # estimate error using k-fold cross validation\n",
    "    size = len(training_data) // k\n",
    "    for i in range(5):\n",
    "        total_error += 1 - sparse_model.score(not_s[(i*size):(i*size+size),j:j+1], training_labels[(i*size):(i*size+size)])\n",
    "    average_error = total_error / 5\n",
    "    if average_error < min_error:\n",
    "        min_error = average_error\n",
    "        min_feature = j\n",
    "\n",
    "print('Feature selected at k = 1: ' + not_s_feature_names[min_feature])\n",
    "\n",
    "# move the name of feature selected from the feature not in s to in s\n",
    "s_feature_names = not_s_feature_names[min_feature:min_feature+1]\n",
    "not_s_feature_names = np.delete(not_s_feature_names, min_feature)\n",
    "\n",
    "# move the actual feature from not in s to in s\n",
    "s = not_s[:, min_feature:min_feature+1]\n",
    "not_s = np.delete(not_s, min_feature, axis=1)\n",
    "\n",
    "# find all the next features to be in S\n",
    "for h in range(len(not_s[0])):\n",
    "    min_error = 1\n",
    "    min_feature = 0\n",
    "    for j in range(len(not_s[0])):\n",
    "        k = 5\n",
    "        total_error = 0\n",
    "\n",
    "        sparse_model = linear_model.LogisticRegression(max_iter=1000).fit(np.hstack((s, not_s[:,j:j+1])), training_labels)\n",
    "\n",
    "        size = len(training_data) // k\n",
    "        for i in range(5):\n",
    "            total_error += 1 - sparse_model.score(np.hstack((s[(i*size):(i*size+size)], not_s[(i*size):(i*size+size),j:j+1])), training_labels[(i*size):(i*size+size)])\n",
    "        average_error = total_error / 5\n",
    "        if average_error < min_error:\n",
    "            min_error = average_error\n",
    "            min_feature = j\n",
    "\n",
    "    print('Feature selected at k = ' + str(h+2) + ': ' + not_s_feature_names[min_feature])\n",
    "\n",
    "    s_feature_names = np.append(s_feature_names, not_s_feature_names[min_feature])\n",
    "    not_s_feature_names = np.delete(not_s_feature_names, min_feature)\n",
    "    s = np.hstack((s, not_s[:, min_feature:min_feature+1]))\n",
    "    not_s = np.delete(not_s, min_feature, axis=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
